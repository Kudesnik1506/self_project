{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Восстановление золота из золотосодержащей руды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание\n",
    "\n",
    "Компания \"Цифра\" разрабатывает решения для эффективной работы промышленных предприятий. Одной из задач является необходимость научиться предсказывать коэффициент восстановления золота из руды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заказчик:\n",
    "- \"Цифра\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные данные:\n",
    "\n",
    "- данные о технологическом процессе и параметрах этапов проведения технологического процесса очистки золота"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача:\n",
    "- построить модель предсказания коэффициента восстановления золота из руды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План работы:\n",
    "- Загрузить и подготовить (предобработать) данные. \n",
    "- проанализировать данные.\n",
    "- построить модель.\n",
    "- Описать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "## <a href='#section01'>1. Изучение общей информации</a>\n",
    "* <a href='#section1'>1. Загрузка библиотек и функций, чтение информации</a>\n",
    "* <a href='#section2'>2. Просмотр данных</a>\n",
    "* <a href='#section3'>3. Выявление аномалий</a>\n",
    "* <a href='#section4'>4. Вывод</a>\n",
    "\n",
    "## <a href='#section02'>2. Исследовательская часть</a>\n",
    "* <a href='#section21'>1. Предобработка</a>\n",
    "* <a href='#section22'>2. Анализ изменения концентрации металлов</a>\n",
    "* <a href='#section23'>3. Анализ распределения размеров гранул сырья</a>\n",
    "* <a href='#section24'>4. Анализ суммарной концентрации всех веществ на разных стадиях</a>\n",
    "* <a href='#section25'>5. Вторичная предобработка</a>\n",
    "* <a href='#section26'>6. Подготовка данных</a>\n",
    "* <a href='#section27'>7. Обучение модели</a>\n",
    "\n",
    "## <a href='#section03'>3. Итоговый вывод</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных:\n",
    "\n",
    "#### Признаки\n",
    "- date — дата проведения операции\n",
    "- все остальные бесконечные и непонятные признаки\n",
    "\n",
    "#### Целевой признак\n",
    "- rougher.output.recovery - эффективность обогащения чернового концентрата\n",
    "- final.output.recovery — эффективноть обогащения финального концентрата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid #000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=section01>1. Изучение общей информации</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section1>1. Загрузка библиотек и функций, чтение информации</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирую все необходимые для проекта библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats as st\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import SCORERS as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяю константы, которые будут участвовать в проекте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP_SIZE = 5000   \n",
    "SHAPIRO_LIMIT = 5000    \n",
    "state = np.random.RandomState(12345)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настраиваю параметры отображения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 90)\n",
    "pd.set_option('display.max_rows', 90)\n",
    "mpl.rcParams['axes.titlesize'] = 15\n",
    "mpl.rcParams['axes.titleweight'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирую библиотеки и вывожу команды для исключения предупреждений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузил библиотеки и необходимые настройки. Теперь определяю функции, которые необходимы для решения задач проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value(df):\n",
    "    count = []\n",
    "    missing_value = pd.DataFrame(columns=['NaN_part', 'empty_counts', 'space_counts', '0_counts', '-1_counts', 'unique_counts',\\\n",
    "                                          'min_value', 'max_value', 'dupl_sum', 'dtypes', 'length'], index=df.columns)\n",
    "    for i in df.columns: \n",
    "        missing_value['NaN_part'][i] = df[i].isnull().mean()\n",
    "        missing_value['empty_counts'][i] = df[df[i] == ''][i].count()\n",
    "        missing_value['space_counts'][i] = df[df[i] == ' '][i].count()\n",
    "        missing_value['0_counts'][i] = df[(df[i] == 0)][i].count()\n",
    "        missing_value['-1_counts'][i] = df[df[i] == -1][i].count()\n",
    "        missing_value['unique_counts'][i] = len(df[i].unique())\n",
    "        missing_value['min_value'][i] = df[i].min()\n",
    "        missing_value['max_value'][i] = df[i].max()\n",
    "        missing_value['dupl_sum'][i] = df[i].duplicated().sum()\n",
    "        missing_value['dtypes'][i] = df[i].dtypes\n",
    "        missing_value['length'][i] = len(df[i])\n",
    "        \n",
    "    for i in missing_value.columns:\n",
    "        count.append(missing_value[missing_value[i] != 0][i].count())\n",
    "\n",
    "    missing_value.loc['count_not_0'] = count\n",
    "    return(missing_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция поиска аномалий в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduction_data(list_df, trigger):\n",
    "    for df in list_df:\n",
    "        try:\n",
    "            if trigger == 0:\n",
    "                print('-----------------------------------------------------------')\n",
    "                print('Данные о таблице {}:'.format(df.name))\n",
    "                print('-----------------------------------------------------------')\n",
    "                print(df.info())\n",
    "            if trigger == 1:\n",
    "                print('Данные о таблице: {}'.format(df.name))\n",
    "                display(df.head())\n",
    "            if trigger == 2:\n",
    "                print('Данные о таблице: {}'.format(df.name))\n",
    "                display(df.describe())\n",
    "        except:\n",
    "            print('ERROR! Выберите один из 3 вариантов:')\n",
    "            print('вывести info() - выбери 0')\n",
    "            print('вывести первые 5 строк - выбери 1')\n",
    "            print('вывести describe() - выбери 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция просмотра данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inspection(df, nrows=10, ncols=4, bins=50, trigger=1):\n",
    "    fig = plt.figure(figsize=(0.8*nrows, 15*ncols), facecolor=('gray')) \n",
    "    #fig.suptitle('Распределение и ящик с усами признаков', fontsize=16)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.7)\n",
    "    subplots = 1\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if trigger == 1:\n",
    "            ax = fig.add_subplot(nrows, ncols, subplots)\n",
    "            ax = df[feature].hist(bins=bins, color='y', density=True, alpha=0.9)\n",
    "            ax.axvline(x=df[feature].mean(), color='b')\n",
    "            ax.axvline(x=df[feature].median(), color='r')    \n",
    "            ax.set_title(df[feature].name, fontsize=10)\n",
    "            ax.set_facecolor('#eafff5')\n",
    "            ax.grid()\n",
    "            subplots +=1\n",
    "        elif trigger == 0:\n",
    "            ax = fig.add_subplot(nrows, ncols, subplots)\n",
    "            sns.boxplot(data=df, x=df[feature], color='b', ax=ax)   \n",
    "            ax.set_title(df[feature].name.title(), fontsize=14)\n",
    "            ax.set_facecolor('#eafff5')\n",
    "            ax.grid(None)\n",
    "            subplots +=1\n",
    "        else:\n",
    "            print('Trigger may be only 0 or 1. Please, change it')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция визуального просмотра одного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inspection_2(df, df2, nrows=10, ncols=4, bins=50, trigger=1):\n",
    "    fig = plt.figure(figsize=(0.8*nrows, 15*ncols), facecolor=('gray')) #надо подобрать грамотно коэффициент\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.7)\n",
    "    subplots = 1\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if trigger == 1:\n",
    "            ax = fig.add_subplot(nrows, ncols, subplots)\n",
    "            ax = df[feature].hist(bins=bins, color='y', density=True, alpha=0.9)\n",
    "            df2[feature].hist(bins=bins, color='g', density=True, alpha=0.9)   \n",
    "            ax.set_title(df[feature].name, fontsize=10)\n",
    "            ax.legend(['df1', 'df2'], loc='upper right')\n",
    "            ax.set_facecolor('#eafff5')\n",
    "            ax.grid()\n",
    "            subplots +=1\n",
    "        elif trigger == 0:\n",
    "            ax = fig.add_subplot(nrows, ncols, subplots)\n",
    "            sns.boxplot(data=df, x=df[feature], color='b', ax=ax)   \n",
    "            ax.set_title(df[feature].name.title(), fontsize=14)\n",
    "            ax.set_facecolor('#eafff5')\n",
    "            ax.grid(None)\n",
    "            subplots +=1\n",
    "        else:\n",
    "            print('Trigger may be only 0 or 1. Please, change it')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция визуального просмотра двух датасетов на одном графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_2genpop(sample_1, sample_2, alpha=0.05, param_test=True): \n",
    "    print(f'Количество наблюдений в выборках на входе: {len(sample_1)}, {len(sample_2)}')\n",
    "    if param_test == True:\n",
    "        if len(sample_1) > SHAPIRO_LIMIT:\n",
    "            sample1 = bootstrap_median(sample_1, BOOTSTRAP_SIZE, SHAPIRO_LIMIT)\n",
    "        if len(sample_2) > SHAPIRO_LIMIT:\n",
    "            sample2 = bootstrap_median(sample_2, BOOTSTRAP_SIZE, SHAPIRO_LIMIT)\n",
    "        if (len(sample_1) <= SHAPIRO_LIMIT) and (len(sample_2) <= SHAPIRO_LIMIT):\n",
    "            sample1 = sample_1\n",
    "            sample2 = sample_2\n",
    "\n",
    "        shapiro_test1 = st.shapiro(sample1.dropna())\n",
    "        shapiro_test2 = st.shapiro(sample2.dropna())\n",
    "        print(f'Тест Шапиро-Уилка показал: тест1 {shapiro_test1}, тест2 {shapiro_test2}')\n",
    "        \n",
    "        levene_test = st.levene(sample_1.dropna(), sample_2.dropna())\n",
    "        equal_var = True if (levene_test.pvalue >= alpha) else False\n",
    "        print(f'equal_var={equal_var}')\n",
    "\n",
    "        results = st.ttest_ind(sample_1.dropna(), sample_2.dropna(), equal_var=equal_var)\n",
    "        hypothesis = 'H0' if (results.pvalue >= alpha) else 'H1' if (results.pvalue < alpha) else None\n",
    "        print(f'Статистический параметрический тест для 2 независимых выборок: {hypothesis}')\n",
    "      \n",
    "    elif param_test == False:            \n",
    "        mann_test = st.mannwhitneyu(sample_1.dropna(), sample_2.dropna())\n",
    "        hypothesis = 'H0' if (mann_test.pvalue >= alpha) else 'H1' if (mann_test.pvalue < alpha) else None\n",
    "        print(f'Статистический непараметрический тест для 2 независимых выборок: {hypothesis}')\n",
    "    else:\n",
    "        print('Параметр param_test может иметь значения только True or False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция определения статистического различия выборок (pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_2genpop_list(df1, df2, alpha=0.05, param_test=True):\n",
    "    print(f'Количество наблюдений в выборках на входе: {len(df1)}, {len(df2)}, \\\n",
    "          количество признаков: {len(df1.columns), len(df2.columns)} \\n')\n",
    "    \n",
    "    if param_test == True:\n",
    "        test_value = pd.DataFrame(columns=['shapiro_test1', 'shapiro_test2','equal_var', 'ttest'], index=df1.columns)\n",
    "        for feature in df1.columns:\n",
    "            if len(df1) > SHAPIRO_LIMIT:\n",
    "                sample1 = bootstrap_median(df1[feature], BOOTSTRAP_SIZE, SHAPIRO_LIMIT)\n",
    "            if len(df2) > SHAPIRO_LIMIT:\n",
    "                sample2 = bootstrap_median(df2[feature], BOOTSTRAP_SIZE, SHAPIRO_LIMIT)\n",
    "            if (len(df1) <= SHAPIRO_LIMIT) and (len(df2) <= SHAPIRO_LIMIT):\n",
    "                sample1 = df1[feature]\n",
    "                sample2 = df2[feature]\n",
    "\n",
    "            shapiro_test1 = st.shapiro(sample1.dropna())\n",
    "            shapiro_test2 = st.shapiro(sample2.dropna())\n",
    "            test_value['shapiro_test1'][feature] = shapiro_test1\n",
    "            test_value['shapiro_test2'][feature] = shapiro_test2\n",
    "\n",
    "            levene_test = st.levene(df1[feature].dropna(), df2[feature].dropna())\n",
    "            equal_var = True if (levene_test.pvalue >= alpha) else False\n",
    "            test_value['equal_var'][feature] = equal_var\n",
    "\n",
    "            results = st.ttest_ind(df1[feature].dropna(), df2[feature].dropna(), equal_var=equal_var)\n",
    "            test_value['ttest'][feature] = 'H0' if (results.pvalue >= alpha) else 'H1' if (results.pvalue < alpha) else None\n",
    "\n",
    "    elif param_test == False:\n",
    "        test_value = pd.DataFrame(columns=['mann_test'], index=df1.columns)      \n",
    "        for feature in df1.columns:\n",
    "            mann_test = st.mannwhitneyu(df1[feature].dropna(), df2[feature].dropna())\n",
    "            test_value['mann_test'][feature] = 'H0' if (mann_test.pvalue >= alpha) else 'H1' if (mann_test.pvalue < alpha) else None\n",
    "    else:\n",
    "        print('Параметр param_test может иметь значения только True or False')\n",
    "        \n",
    "    display(test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция определения статистического различия групп выборок (pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficiency(C, F, T, df):\n",
    "    rougher_efficiency = C * (F - T) / (F * (C - T)) * 100\n",
    "    MAE = mean_absolute_error(df, rougher_efficiency)\n",
    "    print(f'Средняя абсолютная ошибка MAE = {MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция расчета эффективности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_median(sample, count, n):\n",
    "    values = []\n",
    "    for i in range(count):\n",
    "        subsample = sample.sample(n=n, replace=True, random_state=state) \n",
    "        values.append(subsample.median())\n",
    "    return(pd.Series(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция распределения медиан в любой выборке по методу bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все функции определены, выгружаю данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    train = pd.read_csv('datasets/gold_recovery_train.csv')\n",
    "    test = pd.read_csv('datasets/gold_recovery_test.csv')\n",
    "    full = pd.read_csv('datasets/gold_recovery_full.csv')\n",
    "except:\n",
    "    train = pd.read_csv('/datasets/gold_recovery_train.csv')\n",
    "    test = pd.read_csv('/datasets/gold_recovery_test.csv')\n",
    "    full = pd.read_csv('/datasets/gold_recovery_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section2>2. Просмотр данных</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.name = 'train'\n",
    "test.name = 'test'\n",
    "full.name = 'full'\n",
    "list_df = [train, test, full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_data(list_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_data(list_df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section3>3. Выявление аномалий</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрю наличие аномалий в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value = missing_value(train)\n",
    "display(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "value = missing_value(test)\n",
    "display(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value = missing_value(full)\n",
    "display(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрю качественные характеристики нормальности распределения. Для этого переведу в индекс признак 'date'. Он необходим для проведения качественного  и количественного тестов. Создам копию, чтобы можно было обращаться в будущем к исходным данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_copy = full.copy()\n",
    "train_copy = train.copy()\n",
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [full, train, test]:\n",
    "    df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создам датасет full размером с train. Это необходимо будет для проведения статистических тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_full = full.loc[train.index]\n",
    "#part_train = train.loc[test.index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете test даты отличны от других датасетов, они смещены на 1 сек. Поэтому я не смог создать выборку train размера выборки test. Надо будет проверить даты на нерваность временного ряда и одинаковый шаг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspection(full, nrows=22, ncols=4, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspection_2(full, train, 22, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Странно, визуально final.output.recovery имеет нормальное распределение, но qq plot не подтверждает этого.\n",
    "\n",
    "Визуально распределения концентрации металлов на финальном этапе в наборах данных full and train похожи, различаются моды и есть небольшие смещения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть на различия между датасетами train and test я пока не могу - необходимо разобраться с датами, они не совпадают.\n",
    "\n",
    "Посмотрю количественные характеристики нормальности распределения статистическими параметрическими тестами для независимых выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hypothesis_2genpop_list(full, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- если рассмотреть все тот же признак final.output.recovery, то статистические параметрические тесты тоже не показали нормальность распределения. Хотя визуально ряд признаков выглядят вполне как нормальное распределение.\n",
    "- тесты Шапиро-Уилка показал значимое различие многих признаков от распределения Гаусса.\n",
    "\n",
    "Как результат, статистические параметрические тесты нельзя использовать, практически все распределения признаков имеют значимое отличие от Гауссова. Посмотрю на непараметрические тесты для независимых выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_2genpop_list(full, train, param_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непараметрический тест Манна-Уитни для независимых выборок в целом показал, что распределения значимо отличаются. То есть они не являются нормальными, и при этом имеют значимых различия между собой. Исключением являются только признаки:\n",
    "\n",
    "- primary_cleaner.input.depressant\n",
    "- primary_cleaner.output.tail_ag\n",
    "- rougher.output.concentrate_pb\n",
    "- rougher.output.tail_pb\n",
    "- rougher.state.floatbank10_b_air\n",
    "- rougher.state.floatbank10_c_air\n",
    "- rougher.state.floatbank10_c_level\n",
    "- rougher.state.floatbank10_e_level\n",
    "- secondary_cleaner.output.tail_pb\n",
    "- secondary_cleaner.state.floatbank2_b_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо убедиться в том, что признаки не коррелируют между собой. Для этого посмотрю на корреляцию данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr_stacked = train.corr().unstack().sort_values(ascending=False).reset_index()\n",
    "train_corr_stacked.columns=['features_1', 'features_2', 'corr']\n",
    "\n",
    "collinear_features = train_corr_stacked.query('corr > 0.7')\n",
    "collinear_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я рассматриваю производственный процесс, в котором операции проходят последовательно. Поэтому корреляция должна быть между этапами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section4>4. Вывод</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аномалии:\n",
    "    \n",
    "- наличие NaN\n",
    "- количество NaN повторяемо по признакам, скорее всего для рада признаков имеют одну причину\n",
    "- наличие множества выбросов\n",
    "- все распределения не являются Гауссовым по Q-Q plot и статистическим параметрическим тестам. Но визуально распределения кажутся нормальными. Непараметрические статистические тесты показывают, что ряд признаков имеет одинаковость распределения\n",
    "- наличие скошенности\n",
    "- наличие эксцессов, которые визуально подтверждаются не для всех признаков\n",
    "- date имеет тип данных object\n",
    "- временные смещения в датасете test\n",
    "- возможные разные временные шаги и временые разрывы\n",
    "- мультиколлинеарность, которую возможно вообще не стоит обрабатывать, так как производственный процесс линеен и зависит от предыдущих этапов. \n",
    "\n",
    "Вывод:\n",
    "    \n",
    "- обработать NaN практически во всех признаках всех столбцов\n",
    "- изменить тип данных признака date (или в индекс его)\n",
    "- проверить неразрывность и одношаговость даты в test\n",
    "- параметрические статистические тесты нельзя использовать, надо пробовать непараметрические\n",
    "- спросить у Заказчина более подробно информацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid #000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=section02>2. Исследовательская часть</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### п. 1.2. Проверю эффективность обогащения на этапе флотации на обучающей выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = train['rougher.input.feed_au']         #доля золота в сырье/концентрате до флотации\n",
    "C = train['rougher.output.concentrate_au'] #доля золота в концентрате после флотации\n",
    "T = train['rougher.output.tail_au']        #доля золота в отвальных хвостах после флотации\n",
    "\n",
    "# efficiency(C, F, T, train['rougher.output.recovery'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я скрыл в комментарии последнюю строчку, так как не получилось рассчитать эффективность из-за обилия расчетных NaNов. Они не находятся в датасете и являются результатом вычисления. Причина скорее всего в том, что в оригинальном наборе данных из-за невозможности расчета эффективности обогащения была произведена замена некоторых наблюдений на константные величины. Таким образом был решен вопрос с узким местом склеивания реальных данных с формулой.\n",
    "\n",
    "Надо оценить эффективность без учета этих данных. Для это произведу удаление этих наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drop = train.dropna(how='any', subset=['rougher.output.recovery'])\n",
    "\n",
    "F = train_drop['rougher.input.feed_au']         #доля золота в сырье до флотации\n",
    "C = train_drop['rougher.output.concentrate_au'] #доля золота в концентрате после флотации\n",
    "T = train_drop['rougher.output.tail_au']        #доля золота в отвальных хвостах после флотации\n",
    "\n",
    "efficiency(C, F, T, train_drop['rougher.output.recovery'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE практически не отличается, поэтому можно утверждать, что эффективность была посчитана по заданной формуле. Кроме того, там где в наборе данных были NaNы эффективность считалась скорее всего подставлением константных переменных исходя из каких-то профессиональных соображений.\n",
    "\n",
    "Вообще анализ формулы эффективности обогащения приводит к следующим выводам:\n",
    "- recovery -> 0 => все золото ушло в хвост, что говорит о низкой эффективности обогащения.\n",
    "- recovery -> 1 => имею идеальную очистку. Примеси уходят в хвост, а золото остается.\n",
    "- recovery -> ∞ => золота уже не было на этапе очистки, процесс идет вхолостую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обобщу результат работы:\n",
    "    \n",
    "- предобработка выполнена\n",
    "- выявлены большие хвосты выбросов практически для всех признаков всех наборов данных. При этом существуют правые хвосты\n",
    "- есть ложные наблюдения, к примеру концентрация золота после этапа первичной очистки равна 0, а на финальном этапе имеет численное значение.\n",
    "- есть данные, расчетных характеристики от которых нельзя вычислить, но в датасетах они имеют численное значение. Назову их скрытыми NaN.\n",
    "\n",
    "### п. 1.3. Выведу признаки, которых нет в тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns.difference(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_in_test = [i for i in train.columns if i in test.columns]\n",
    "# print(pd.Index(columns_in_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки, которые не вошли в тестовую выборку можно разбить на блоки:\n",
    "    \n",
    "- final.output\n",
    "- primary_cleaner.output\n",
    "- secondary_cleaner.output\n",
    "- rougher.calculation\n",
    "- rougher.output\n",
    "\n",
    "Вошедшие в выборку test признаки:\n",
    "    \n",
    "- primary_cleaner.input\n",
    "- весь state\n",
    "- rougher.input\n",
    "\n",
    "Можно сделать вывод, что в выборке test данные о сырье, реагентах и текущем состоянии параметров этапов: объема воздуха, уровня жидкости, размер гранул сырья и скорости подачи сырья. В test нет выходных данных output и расчетных характеристик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section21>1. Предобработка</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверю временной интервал на разрывность и одношаговость. Так как в оригинале я дату перевел в индекс, то посмотрю в копии датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_copy.name = 'full'\n",
    "train_copy.name = 'train'\n",
    "test_copy.name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [full_copy, train_copy, test_copy]:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    time_min = df['date'].diff().min()\n",
    "    time_max = df['date'].diff().max()\n",
    "    print(f'В датасете {df.name} шаг составляет max={time_max} - min={time_min} = {time_max - time_min}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- в выборке full and train шаг разнороден: 59:59 мин и 1 час - смещение на 1 сек\n",
    "- в выборке test шаг однороден - 1 час\n",
    "- в датасете train и test есть временные разрывы. Длительность разрыва достигает 4 и 8 месяцев\n",
    "\n",
    "Скорее всего разрывы обусловлены тем, что в train and test добавлялись наблюдения из full не блоком, а случайным образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я заменю все пропуски в train and test исходя из тех соображений, что full является их прародителем. Если после разделения train and test были изменены, то мой подход не правилен. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.update(full, overwrite=False)\n",
    "test.update(full, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь заполню оставшиеся пропуски методами bfill() and ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.ffill().bfill()\n",
    "test = test.ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверю результат замены пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = missing_value(train)\n",
    "value[0:len(value):len(value)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = missing_value(test)\n",
    "value[0:len(value):len(value)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Промежуточный вывод\n",
    "    \n",
    "- есть разрыв и смещение в дате\n",
    "- в train and test from full данные передавались случайным образом\n",
    "- часть пропусков в train and test заполнил из full\n",
    "- заполнил остальные пропуски методами ffill() and bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section22>2. Анализ изменения концентрации металлов</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### п. 2.1. Посмотрю, как меняется концентрация металлов на различных этапах очистки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrate = {'ag':['rougher.output.concentrate_ag', 'primary_cleaner.output.concentrate_ag', 'final.output.concentrate_ag' ],\n",
    "               'au':['rougher.output.concentrate_au', 'primary_cleaner.output.concentrate_au', 'final.output.concentrate_au' ],\n",
    "               'pb':['rougher.output.concentrate_pb', 'primary_cleaner.output.concentrate_pb', 'final.output.concentrate_pb' ],\n",
    "               'sol':['rougher.output.concentrate_sol', 'primary_cleaner.output.concentrate_sol', 'final.output.concentrate_sol']}\n",
    "\n",
    "fig = plt.figure(figsize=(16, 5), facecolor=('gray')) \n",
    "fig.suptitle(f'Распределение значений концентрации металлов на разных этапах ', fontsize=16)\n",
    "plt.axis('off')\n",
    "subplots = 1\n",
    "\n",
    "for key in concentrate:\n",
    "    ax = fig.add_subplot(1, 4, subplots)\n",
    "    sns.boxplot(data=full[concentrate[key]], color='b', ax=ax)   \n",
    "    ax.set_title(f'Концентрация {key}', fontsize=14)\n",
    "    ax.set_facecolor('#eafff5')\n",
    "    ax.grid(None)\n",
    "    ax.set_xticklabels([])\n",
    "    subplots +=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 5), facecolor=('gray')) \n",
    "fig.suptitle(f'Распределение значений концентрации металлов на разных этапах ', fontsize=16)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "subplots = 1\n",
    "\n",
    "for key in concentrate:\n",
    "    ax = fig.add_subplot(1, 4, subplots)\n",
    "    for i in range(0, 3):\n",
    "        ax = full[concentrate[key][i]].plot(kind='hist', bins=50, grid=True) \n",
    "        ax = plt.axvline(x=full[concentrate[key][i]].median(), linewidth=1, color='r', label='mean')\n",
    "    plt.title(f'Концентрация {key}', fontsize=14)\n",
    "    subplots += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Медиана концентрации золота с каждым этапом увеличивается, примерно с 20 до 45. Это говорит о том, что технологический процесс работает хорошо. Очистка золота положительна. При этом график распределения золота сужается, что так же хорошо - увеличивается устойчивость вероятного прогноза.\n",
    "\n",
    "Медиана концентрации серебра понижается примерно с 12 до 5. Видимо серебро участвует в химической реакции и является расходным веществом. После второй очистки распределение серебра сужается. \n",
    "\n",
    "Медиана свинца после первой очистки повысилась, видимо на этих этапах он активно использовался. После второй очистки медиана практически не изменилась, а распределение относительно нее стало таким же как было на этапе флотации. Можно говорить о некотором скачке медианы распределения концентрации свинца после первой очистки.\n",
    "\n",
    "Медиана концентрации неизвестного вещества sol понижалась примерно с 30 до 8. Могу предположить, что оно являлось расходным материалом для обогащения золота.\n",
    "\n",
    "К финальному этапу распределения всех металлов сужаются, повышается устойчивость прогноза, что я расцениваю позитивно. При этом каждое распределение имеет большие хвосты около 0. Предположу, что причиной могут быть:\n",
    "- ошибочные прогнозы концентрации металлов\n",
    "- программные ошибки расчетов в технологическом процессе\n",
    "- ошибочные данные о наличии золота в руде и т. д.\n",
    "\n",
    "Вывод - хвосты надо обрабатывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section23>3. Анализ распределения размеров гранул сырья</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### п. 2.2 Рассмотрю распределения размеров гранул сырья на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_train = pd.DataFrame(train[[x for x in train.columns if 'feed_size' in x]])\n",
    "feed_test = pd.DataFrame(test[[x for x in test.columns if 'feed_size' in x]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки 2х выборок имеют различные размеры. Состав набора данных также различен. Удалю лишние признаки и возьму из выборки train измерения, соответствующие измерениям выборки test по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspection(feed_train, 20, 4, trigger=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspection(feed_test, 20, 4, trigger=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspection_2(feed_train, feed_test, 20, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуальный анализ распределения размера гранул сырья показывает:\n",
    "- размахи идентичны на этапе флотации. На этапе первичной обработки разнятся, но на уровне выбросов\n",
    "- есть выбросы с левой и правой стороны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаю статистические различия для пар размеров гранул сырья как для независимых выборок. Буду рассматривать выборки одинаковой длины. То есть от выборки train я буду использовать только четверть данных, которые сохранил в датасет part_feed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_2genpop(train['rougher.input.feed_size'].dropna(), test['rougher.input.feed_size'].dropna(), param_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гипотеза о равенстве двух средних признаков отклонена, статистический параметрический анализ показывает, что средние значимо не равны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_2genpop(train['rougher.input.feed_size'].dropna(), test['rougher.input.feed_size'].dropna(), param_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гипотеза о равенстве двух средних признаков отклонена, статистический непараметрический анализ показывает, что средние также значимо не равны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Промежуточный вывод:\n",
    "    \n",
    "- Сравнение распределения гранул сырья привело к позитивным выводам. Распределения в целом похожи друг на друга. Есть различия в выбросах с разных сторон.\n",
    "- необходимо обработать выбросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section24>4. Анализ суммарной концентрации всех веществ на разных стадиях</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### п.2.3. Исследую суммарную концентрацию всех веществ на разных стадиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrate_input = pd.DataFrame(full[[x for x in full.columns if 'rougher.input.feed' in x]], index=full.index)\n",
    "concentrate_rougher = pd.DataFrame(full[[x for x in full.columns if 'rougher.output.concentrate' in x]])\n",
    "concentrate_primary_cleaner = pd.DataFrame(full[[x for x in full.columns if 'primary_cleaner.output.concentrate' in x]])\n",
    "concentrate_final = pd.DataFrame(full[[x for x in full.columns if 'final.output.concentrate' in x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrate_input = concentrate_input.drop(['rougher.input.feed_rate', 'rougher.input.feed_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrate_sum = pd.DataFrame(index=concentrate_input.index)\n",
    "concentrate_sum['input_sum'] = concentrate_input.sum(axis=1)\n",
    "concentrate_sum['rougher_sum'] = concentrate_rougher.sum(axis=1)\n",
    "concentrate_sum['primary_cleaner_sum'] = concentrate_primary_cleaner.sum(axis=1)\n",
    "concentrate_sum['final_sum'] = concentrate_final.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5), facecolor=('gray'))\n",
    "fig.suptitle(f'Суммарная концентрация всех веществ на разных стадиях')\n",
    "ax = plt.figure(figsize=(16, 5), facecolor=('gray'))\n",
    "for i in concentrate_sum:\n",
    "    ax = concentrate_sum[i].plot(kind='hist', bins=200, legend=True, grid=True)\n",
    "    ax = plt.axvline(concentrate_sum[i].median(), color='green', linewidth=0.5, label='median')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- медианы суммарной концентрации rougher_sum and final_sum сливаются на графике. Они практически одинаковы\n",
    "\n",
    "Необходима вторая предобработка:\n",
    "- удалить экстремальные выбросы\n",
    "- удалить ложные наблюдения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section25>5. Вторичная предобработка</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалю те значения концентрации веществ на разных стадиях, сумма которых меньше 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train = len(train)\n",
    "length_test = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrate_sum_indexes = concentrate_sum[np.sum(concentrate_sum, axis=1) > 0.0].index\n",
    "train_preprocessed = train[train.index.isin(concentrate_sum_indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'было потеряно {(length_train - len(train_preprocessed)) / length_train * 100:.2f}% данных')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = missing_value(train_preprocessed)\n",
    "value[0:len(value):len(value)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остались еще нулевые значения. Возможно стоит их обработать, но пока не понимаю как"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section26>6. Подготовка модели</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Напишу функции расчета метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(target, predict):\n",
    "    summary = 200 / len(target) * np.sum(abs(target - predict) / (abs(target) + abs(predict))) \n",
    "    return(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_total(rougher_target, rougher_predict, final_target, final_predict):    \n",
    "    return(0.25 * smape(rougher_target, rougher_predict) + 0.75 * smape(final_target, final_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовлю модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьму в обучающий датасет те данные, которые в test. Насколько я понял, это необходимо из-за специфики бизнеса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_preprocessed[test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделю целевые признаки и добавлю их в train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_target = full[['final.output.recovery', 'rougher.output.recovery']]\n",
    "train = pd.concat([train, full_target], join='inner', axis=1)\n",
    "test = pd.concat([test, full_target], join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удалю пропуски в целевых признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'было потеряно в train {(length_train - len(train)) / length_train * 100:.2f}% данных')\n",
    "print(f'было потеряно в test {(length_test - len(test)) / length_test * 100:.2f}% данных')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = missing_value(train)\n",
    "value[0:len(value):27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = missing_value(test)\n",
    "value[0:len(value):27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_rougher = train['rougher.output.recovery']\n",
    "target_train_final = train['final.output.recovery']\n",
    "target_test_rougher = test['rougher.output.recovery']\n",
    "target_test_final = test['final.output.recovery']\n",
    "features_train = train.drop(['rougher.output.recovery', 'final.output.recovery'], axis=1)\n",
    "features_test = test.drop(['rougher.output.recovery', 'final.output.recovery'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отмасштабирую данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "\n",
    "features_train_scaled = pd.DataFrame(scaler.transform(features_train), columns=features_train.columns)\n",
    "features_test_scaled = pd.DataFrame(scaler.transform(features_test), columns=features_test.columns)\n",
    "print(features_train_scaled.shape)\n",
    "print(features_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=section27>7. Обучение модели</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логично предположить, что обучать rougher надо на данных, полученных до флотации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_rougher = features_train_scaled[[i for i in features_train_scaled.columns if 'rougher' in i]]\n",
    "features_train_final = features_train_scaled\n",
    "features_test_rougher = features_test_scaled[[i for i in features_test_scaled.columns if 'rougher' in i]]\n",
    "features_test_final = features_test_scaled\n",
    "print(features_train_rougher.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создам собственную метрику на основе формулы расчета эффективности обогащения золота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_scorer = make_scorer(smape, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценю результаты простой модели на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_dummy_rougher = DummyRegressor(strategy='median')\n",
    "score_dummy_rougher = abs(cross_val_score(model_dummy_rougher, features_train_rougher, target_train_rougher, cv=1000, \\\n",
    "                                          scoring=smape_scorer).mean())\n",
    "predict_dummy_rougher = pd.Series(cross_val_predict(model_dummy_rougher, features_train_rougher, target_train_rougher, cv=1000))\n",
    "print(f'Простая dummy-модель на этапе флотации: {model_dummy_rougher}, score={score_dummy_rougher:.2f}')\n",
    "\n",
    "model_dummy_final = DummyRegressor(strategy='median')\n",
    "score_dummy_final = abs(cross_val_score(model_dummy_final, features_train_final, target_train_final, cv=1000, \\\n",
    "                                        scoring=smape_scorer).mean())\n",
    "predict_dummy_final = pd.Series(cross_val_predict(model_dummy_final, features_train_final, target_train_final, cv=1000))\n",
    "print(f'Простая dummy-модель на финальном этапе: {model_dummy_final}, score={score_dummy_final:.2f}')\n",
    "\n",
    "smape_total_dummy = smape_total(target_train_rougher, predict_dummy_rougher, target_train_final, predict_dummy_final)\n",
    "print(f'Общая эффективность на простой модели smape_total={smape_total_dummy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучу модель решающих деревьев "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model_dtree_rougher = None\n",
    "best_score_dtree_rougher = 100000\n",
    "best_predict_dtree_rougher = None\n",
    "\n",
    "for depth in range(1, 20, 1):\n",
    "    model_dtree_rougher = DecisionTreeRegressor(random_state=state, max_depth=depth)\n",
    "    predict_dtree_rougher = pd.Series(cross_val_predict(model_dtree_rougher, features_train_rougher, target_train_rougher, cv=20))\n",
    "    score_dtree_rougher = abs(cross_val_score(model_dtree_rougher, features_train_rougher, target_train_rougher, cv=20, scoring=smape_scorer).mean())\n",
    "    \n",
    "    if score_dtree_rougher < best_score_dtree_rougher:\n",
    "        best_score_dtree_rougher = score_dtree_rougher\n",
    "        best_model_dtree_rougher = model_dtree_rougher\n",
    "        best_predict_dtree_rougher = predict_dtree_rougher\n",
    "\n",
    "print(f'Лучшая модельDecisionTree на этапе флотации: {best_model_dtree_rougher}, score={best_score_dtree_rougher:.2f}')\n",
    "\n",
    "best_model_dtree_final = None\n",
    "best_score_dtree_final = 100000\n",
    "best_predict_dtree_final = None\n",
    "\n",
    "for depth in range(1, 20, 1):\n",
    "    model_dtree_final = DecisionTreeRegressor(random_state=state, max_depth=depth)\n",
    "    predict_dtree_final = pd.Series(cross_val_predict(model_dtree_final, features_train_final, target_train_final, cv=20))\n",
    "    score_dtree_final = abs(cross_val_score(model_dtree_final, features_train_final, target_train_final, cv=20, scoring=smape_scorer).mean())\n",
    "    \n",
    "    if score_dtree_final < best_score_dtree_final:\n",
    "        best_score_dtree_final = score_dtree_final\n",
    "        best_model_dtree_final = model_dtree_final\n",
    "        best_predict_dtree_final = predict_dtree_final\n",
    "        \n",
    "print(f'Лучшая модель DecisionTree на финальном этапе: {best_model_dtree_final}, score={best_score_dtree_final:.2f}')\n",
    "\n",
    "smape_total_dtree = smape_total(target_train_rougher, best_predict_dtree_rougher, target_train_final, best_predict_dtree_final)\n",
    "print(f'Общая эффективность на модели DecisionTreeRegressor - smape_total={smape_total_dtree:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверю модель решающих деревьев на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_dtree_rougher = pd.Series(cross_val_predict(best_model_dtree_rougher, features_test_rougher, target_test_rougher, cv=50))\n",
    "predict_test_dtree_final = pd.Series(cross_val_predict(best_model_dtree_final, features_test_final, target_test_final, cv=50))\n",
    "\n",
    "smape_total_dtree_test = smape_total(target_test_rougher, predict_test_dtree_rougher, target_test_final, predict_test_dtree_final)\n",
    "print(f'на тестовой выборке общая эффективность: {smape_total_dtree_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель решающих деревьев на обучающей и тестововй выборке оказалась лучше простой dummy-модели. Попробую обучить модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model_forest_rougher = None\n",
    "best_score_forest_rougher = 10000\n",
    "best_predict_forest_rougher = None\n",
    "for est in range(1, 50, 5):\n",
    "    for depth in range(1, 10, 1):\n",
    "        model_forest_rougher = RandomForestRegressor(random_state=state, n_estimators=est, max_depth=depth)\n",
    "        predict_forest_rougher = pd.Series(cross_val_predict(model_forest_rougher, features_train_rougher, target_train_rougher, cv=20))\n",
    "        score_forest_rougher = abs(cross_val_score(model_forest_rougher, features_train_rougher, target_train_rougher, cv=20, \\\n",
    "                                                  scoring=smape_scorer).mean())\n",
    "        if score_forest_rougher < best_score_forest_rougher:\n",
    "            best_score_forest_rougher = score_forest_rougher\n",
    "            best_model_forest_rougher = model_forest_rougher\n",
    "            best_predict_forest_rougher = predict_forest_rougher\n",
    "print(f'Лучшая модель RandomForest на этапе флотации: {best_model_forest_rougher}, score={best_score_forest_rougher:.2f}')\n",
    "\n",
    "best_model_forest_final = None\n",
    "best_score_forest_final = 10000\n",
    "best_predict_forest_final = None\n",
    "for est in range(1, 50, 5):\n",
    "    for depth in range(1, 10, 1):\n",
    "        model_forest_final = RandomForestRegressor(random_state=state, n_estimators=est, max_depth=depth)\n",
    "        predict_forest_final = pd.Series(cross_val_predict(model_forest_final, features_train_final, target_train_final, cv=20))\n",
    "        score_forest_final = abs(cross_val_score(model_forest_final, features_train_final, target_train_final, cv=20, \\\n",
    "                                                scoring=smape_scorer).mean())\n",
    "        if score_forest_final < best_score_forest_final:\n",
    "            best_score_forest_final = score_forest_final\n",
    "            best_model_forest_final = model_forest_final\n",
    "            best_predict_forest_final = predict_forest_final\n",
    "print(f'Лучшая модель RandomForest на финальном этапе: {best_model_forest_final}, score={best_score_forest_final:.2f}')\n",
    "\n",
    "smape_total_forest = smape_total(target_train_rougher, best_predict_forest_rougher, target_train_final, best_predict_forest_final)\n",
    "print(f'Общая эффективность на модели RandomForest - smape_total={smape_total_forest:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_forest_rougher = pd.Series(cross_val_predict(best_model_forest_rougher, features_test_rougher, target_test_rougher, cv=50))\n",
    "predict_test_forest_final = pd.Series(cross_val_predict(best_model_forest_final, features_test_final, target_test_final, cv=50))\n",
    "\n",
    "smape_total_forest_test = smape_total(target_test_rougher, predict_test_forest_rougher, target_test_final, predict_test_forest_final)\n",
    "print(f'на тестовой выборке общая эффективность: {smape_total_forest_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса на обучающей и тестовой выборках оказалась лучше простой dummy-модели. Попробую обучить модель к-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model_knn_rougher = None\n",
    "best_score_knn_rougher = 10000\n",
    "best_predict_knn_rougher = None\n",
    "for knn in range(1, 30, 1):\n",
    "    model_knn_rougher = KNeighborsRegressor(n_neighbors=knn)\n",
    "    predict_knn_rougher = pd.Series(cross_val_predict(model_knn_rougher, features_train_rougher, target_train_rougher, cv=20))\n",
    "    score_knn_rougher = abs(cross_val_score(model_knn_rougher, features_train_rougher, target_train_rougher, cv=20, scoring=smape_scorer).mean())\n",
    "    if score_knn_rougher < best_score_knn_rougher:\n",
    "        best_score_knn_rougher = score_knn_rougher\n",
    "        best_model_knn_rougher = model_knn_rougher\n",
    "        best_predict_knn_rougher = predict_knn_rougher\n",
    "print(f'Лучшая модель к-случайных соседей {best_model_knn_rougher}, score={best_score_knn_rougher:.2f}')\n",
    "\n",
    "best_model_knn_final = None\n",
    "best_score_knn_final = 1000\n",
    "best_predict_knn_final = None\n",
    "for knn in range(1, 30, 1):\n",
    "    model_knn_final = KNeighborsRegressor(n_neighbors=knn)\n",
    "    predict_knn_final = pd.Series(cross_val_predict(model_knn_final, features_train_final, target_train_final, cv=20))\n",
    "    score_knn_final = abs(cross_val_score(model_knn_final, features_train_final, target_train_final, cv=20, scoring=smape_scorer).mean())\n",
    "    if score_knn_final < best_score_knn_final:\n",
    "        best_score_knn_final = score_knn_final\n",
    "        best_model_knn_final = model_knn_final\n",
    "        best_predict_knn_final = predict_knn_final\n",
    "print(f'Лучшая модель к-случайных соседей {best_model_knn_final}, score={best_score_knn_final:.2f}')\n",
    "\n",
    "smape_total_knn = smape_total(target_train_rougher, best_predict_knn_rougher, target_train_final, best_predict_knn_final)\n",
    "print(f'Общая эффективность на модели KNeighborsRegressor - smape_total={smape_total_knn:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_knn_rougher = pd.Series(cross_val_predict(best_model_knn_rougher, features_test_rougher, target_test_rougher, cv=50))\n",
    "predict_test_knn_final = pd.Series(cross_val_predict(best_model_knn_final, features_test_final, target_test_final, cv=50))\n",
    "\n",
    "smape_total_knn_test = smape_total(target_test_rougher, predict_test_knn_rougher, target_test_final, predict_test_knn_final)\n",
    "print(f'на тестовой выборке общая эффективность: {smape_total_knn_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель к-ближайших соседей на обучающей и тестовой выборке оказалась лучше простой dummy-модели. Попробую обучить линейную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_linear_rougher = LinearRegression()\n",
    "predict_linear_rougher = pd.Series(cross_val_predict(model_linear_rougher, features_train_rougher, target_train_rougher, cv=1000))\n",
    "score_linear_rougher = abs(cross_val_score(model_linear_rougher, features_train_rougher, target_train_rougher, cv=1000, \\\n",
    "                                           scoring=smape_scorer).mean())\n",
    "print(f'Линейная модель на этапе флотации: {model_linear_rougher}, score={score_linear_rougher:.2f}')\n",
    "\n",
    "model_linear_final = LinearRegression()\n",
    "predict_linear_final = pd.Series(cross_val_predict(model_linear_final, features_train_final, target_train_final, cv=1000))\n",
    "score_linear_final = abs(cross_val_score(model_linear_final, features_train_final, target_train_final, cv=1000, \\\n",
    "                                         scoring=smape_scorer).mean())\n",
    "print(f'Линейная модель на финальном этапе:  {model_linear_final}, score={score_linear_final:.2f}')\n",
    "\n",
    "smape_total_linear = smape_total(target_train_rougher, predict_linear_rougher, target_train_final, predict_linear_final)\n",
    "print(f'Общая эффективность на модели RandomForestRegressor - smape_total={smape_total_linear:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_linear_rougher = pd.Series(cross_val_predict(model_linear_rougher, features_test_rougher, target_test_rougher, cv=1000))\n",
    "predict_test_linear_final = pd.Series(cross_val_predict(model_linear_final, features_test_final, target_test_final, cv=1000))\n",
    "\n",
    "smape_total_linear_test = smape_total(target_test_rougher, predict_test_linear_rougher, target_test_final, predict_test_linear_final)\n",
    "print(f'на тестовой выборке общая эффективность: {smape_total_linear_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная модель на обучающей и тестовой выборке оказалась лучше простой dummy-модели. Обобщу результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SmapeTotal = pd.Series()\n",
    "SmapeTotal['dummy'] = smape_total_dummy\n",
    "SmapeTotal['dtree_train'] = smape_total_dtree\n",
    "SmapeTotal['forest_train'] = smape_total_forest\n",
    "SmapeTotal['knn_train'] = smape_total_knn\n",
    "SmapeTotal['linear_train'] = smape_total_linear\n",
    "SmapeTotal['dtree_test'] = smape_total_dtree_test\n",
    "SmapeTotal['forest_test'] = smape_total_forest_test\n",
    "SmapeTotal['knn_test'] = smape_total_knn_test\n",
    "SmapeTotal['linear_test'] = smape_total_linear_test\n",
    "display(SmapeTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таблицы видно, что в данном наборе моделей победила простая линейная модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=section03>3. Итоговый вывод</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения работы были использованы модели регрессии: \n",
    "- решающих деревьев\n",
    "- случайного леса\n",
    "- линейной регрессии\n",
    "- к-ближайших соседей\n",
    "\n",
    "Выявлено было следующее:\n",
    "- Данные оказались c большим количеством пропусков в признаках. \n",
    "- распределение признаков значимо отличается от распределения Гаусса\n",
    "- распределения признаков в датасетах значимо отличаются друг от друга\n",
    "- данные имеют временные разрывы и не являются временным рядом\n",
    "\n",
    "Оценка моделей проводилась по уникальной метрике расчета эффективности обогащения руды\n",
    "\n",
    "В результате исследования я выявил, что на модели линейной регрессии можно добиться наилучшего значения метрики smape_total=8.57. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "473px",
    "width": "387px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
